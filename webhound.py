import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import threading
import time
from termcolor import colored
from urllib.parse import quote
from fake_useragent import UserAgent

SEARCH_ENGINES = {
    "Google": "https://www.google.com/search?q=",
    "DuckDuckGo": "https://duckduckgo.com/html/?q=",
    "Bing": "https://www.bing.com/search?q=",
}

class Scraper:
    def __init__(self):
        self.session = requests.Session()
        self.ua = UserAgent()

    def make_request(self, url):
        headers = {"User-Agent": self.ua.random}
        try:
            response = self.session.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            print(colored(f"âœ… Request to {url} successful. User-Agent: {headers['User-Agent']} ğŸš€", "green"))
            return BeautifulSoup(response.text, "html.parser")
        except requests.exceptions.RequestException as e:
            print(colored(f"âŒ Error making request to {url}: {e} ğŸš¨", "red"))
            return None

    def execute_search(self, query, engine):
        url = SEARCH_ENGINES.get(engine)
        if url:
            print(colored(f"ğŸ”„ Switching to {engine}... ğŸ”„", "cyan"))
            time.sleep(2)

            print(colored(f"ğŸ” Searching on {engine}... ğŸ”", "cyan"))
            start_time = time.time()

            try:
                with ThreadPoolExecutor(max_workers=5) as executor:
                    results = list(executor.map(self.make_request, [f"{url}{quote(query)}&start={i}" for i in range(1, 31, 10)]))

                end_time = time.time()
                print(colored(f"â° Time Elapsed: {end_time - start_time:.2f} seconds â°", "cyan"))

                return results

            except Exception as e:
                print(colored(f"âŒ An error occurred during the search on {engine}: {e} ğŸš¨", "red"))
                return []

    def print_results(self, results, engine):
        if not results:
            print(colored(f"No results from {engine} ğŸ¤·â€â™‚ï¸", "white"))
            return

        print(colored(f"\n{'ğŸ”'*10} Results from {engine} {'ğŸ”'*10}\n", "cyan"))
        for result in results:
            self.print_result(result)

    def print_result(self, result):
        try:
            for item in result.select("div.tF2Cxc, div.result, li.b_algo"):
                title = item.select_one("h2, h3")
                link = item.find("a")["href"]
                description = item.select_one("div.IsZvec, p")

                title_text = title.text.strip().replace(query, colored(query, "red", attrs=['bold'])) if title else "Title not available"
                link_text = colored(link, "cyan").replace(query, colored(query, "red", attrs=['bold'])) if link else "Link not available"
                description_text = description.text.strip().replace(query, colored(query, "red", attrs=['bold'])) if description else "Description not available"

                print(colored(f"\n{'ğŸ”¹'*10} Result {'ğŸ”¹'*10}\n"
                              f"{'ğŸ“– Title:':<15} {colored(title_text, 'yellow')}\n"
                              f"{'ğŸŒ URL:':<15} {link_text}\n"
                              f"{'ğŸ“ Description:':<15} {colored(description_text, 'green')}\n"
                              f"{'ğŸ”¹'*40}\n", "white"))

        except Exception as e:
            print(colored(f"âŒ An error occurred while processing a search result: {e} ğŸš¨", "red"))

if __name__ == "__main__":
    query = input(colored("ğŸ” Enter your query: ", "cyan"))
    scraper = Scraper()

    all_results = []
    for engine in SEARCH_ENGINES:
        results = scraper.execute_search(query, engine)
        all_results.extend(results)

    scraper.print_results(all_results, "All Engines")
