import os
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import time
from termcolor import colored
from urllib.parse import quote
from fake_useragent import UserAgent
from tqdm import tqdm

SEARCH_ENGINES = {
    "Google": "https://www.google.com/search?q=",
    "DuckDuckGo": "https://duckduckgo.com/html/?q=",
    "Bing": "https://www.bing.com/search?q=",
}

class Scraper:
    def __init__(self):
        self.session = requests.Session()
        self.ua = UserAgent()

    def make_request(self, url):
        headers = {"User-Agent": self.ua.random}
        try:
            response = self.session.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            return BeautifulSoup(response.text, "html.parser")
        except requests.exceptions.RequestException as e:
            print(colored(f"Failed to make a request to {url}: {e}", "red"))
            return None

    def execute_search(self, query, engine):
        url = SEARCH_ENGINES.get(engine)
        if url:
            print(colored(f"Switching to {engine}...", "cyan"))
            time.sleep(2)

            print(colored(f"Searching on {engine}...", "cyan"))
            start_time = time.time()

            try:
                with ThreadPoolExecutor(max_workers=5) as executor:
                    search_urls = [f"{url}{quote(query)}&start={i}" for i in range(1, 31, 10)]
                    results = []

                    for result in tqdm(executor.map(self.make_request, search_urls), total=len(search_urls), desc="Progress"):
                        results.append(result)

                end_time = time.time()
                print(colored(f"Search on {engine} completed in {end_time - start_time:.2f} seconds", "cyan"))

                return results

            except Exception as e:
                print(colored(f"An error occurred during the search on {engine}: {e}", "red"))
                return []

    def print_results(self, results, engine):
        if not results:
            print(colored(f"No results from {engine}", "white"))
            return

        print(colored(f"\n{'üîç'*10} Results from {engine} {'üîç'*10}\n", "cyan"))

        visited_links = set()
        result_count = 0

        for result in results:
            try:
                for item in result.select("div.tF2Cxc, div.result, li.b_algo"):
                    title = item.select_one("h2, h3")
                    link = item.find("a")["href"]
                    description = item.select_one("div.IsZvec, p")

                    if link in visited_links:
                        continue

                    visited_links.add(link)
                    result_count += 1

                    title_text = title.text.strip().replace(query, colored(query, "red", attrs=['bold'])) if title else "Title not available"
                    link_text = colored(link, "cyan").replace(query, colored(query, "red", attrs=['bold'])) if link else "Link not available"
                    description_text = description.text.strip().replace(query, colored(query, "red", attrs=['bold'])) if description else "Description not available"

                    print(colored(f"\n{'üîπ'*10} Result {result_count} {'üîπ'*10}\n"
                                  f"{'üìñ Title:':<15} {colored(title_text, 'yellow')}\n"
                                  f"{'üåê URL:':<15} {link_text}\n"
                                  f"{'üìù Description:':<15} {colored(description_text, 'green')}\n"
                                  f"{'üîπ'*40}\n", "white"))

            except Exception as e:
                print(colored(f"An error occurred while processing a search result: {e}", "red"))

        print(colored(f"üî¢ Total Results from {engine}: {result_count}\n", "cyan"))

def print_ascii_banner():
    """Print an artistic ASCII banner."""
    banner = """
    /**\ __  WEB-SEARCH  ______________ ¬©
    * ‚ïî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïó
    * ‚îÇ‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚ñÄ‚ñÄ‚ñë‚ñà‚ñÄ‚ñÑ‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚ñÄ‚ñà‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚ñÄ‚ñà‚ñë‚ñà‚ñÄ‚ñÑ‚îÇ
    * ‚îÇ‚ñë‚ñà‚ñÑ‚ñà‚ñë‚ñà‚ñÄ‚ñÄ‚ñë‚ñà‚ñÄ‚ñÑ‚ñë‚ñà‚ñÄ‚ñà‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚ñë‚ñà‚îÇ
    * ‚îÇ‚ñë‚ñÄ‚ñë‚ñÄ‚ñë‚ñÄ‚ñÄ‚ñÄ‚ñë‚ñÄ‚ñÄ‚ñë‚ñë‚ñÄ‚ñë‚ñÄ‚ñë‚ñÄ‚ñÄ‚ñÄ‚ñë‚ñÄ‚ñÄ‚ñÄ‚ñë‚ñÄ‚ñë‚ñÄ‚ñë‚ñÄ‚ñÄ‚ñë‚îÇ
    * ‚ïö‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïù
    */ ‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢ Information-Gathering ‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢

    | ¬∞ ·¥∞·µâ·µõ·µâÀ°·µí·µñ·µâ ≥ ‚†ò ·¥¨‚Åø·µí‚Åø·∂ú·µÉ·µó·µÉÀ° ∏À¢·µó ‚úì
    | ¬∞ ·¥≥‚Å±·µó·¥¥·µò·µá ‚†ò ·µç‚Å±·µó ∞·µò·µá‚Äß·∂ú·µí·µê/·¥¨‚Åø·µí‚Åø·∂ú·µÉ·µó·µÉÀ° ∏À¢·µó ‚úì
       ‚Ä¢   ‚Ä¢   ‚Ä¢    ______
      ·¥¥·µÉ·µñ·µñ ∏ ·¥ºÀ¢‚Å±‚Åø·µó‚Å±‚Åø·µç! üåêüîç ‚†ò‚Åæ
    """
    print(colored(banner, color="magenta"))

if __name__ == "__main__":
    # Clear screen based on the operating system
    os.system('cls' if os.name == 'nt' else 'clear')
    
    print_ascii_banner()
    query = input(colored("üîç Enter your query: ", "cyan"))
    scraper = Scraper()

    all_results = []
    for engine in SEARCH_ENGINES:
        results = scraper.execute_search(query, engine)
        all_results.extend(results)

    scraper.print_results(all_results, "All Engines")
                                        
